{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from file:///app/apps/sparkoin/sparkoin.jar\n",
      "Finished download of sparkoin.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar file:///app/apps/sparkoin/sparkoin.jar -f\n",
    "import sparkoin._,Sparkoin._ \n",
    "import org.json4s._, jackson.JsonMethods._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val raw = sc.textFile(\"hdfs://hadoop.loc/blockchain/0.json\")\n",
    "val parsed = raw.map(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.hadoop.mapred.InvalidInputException\n",
       "Message: Input path does not exist: hdfs://hadoop.loc/blockchain/0.json\n",
       "StackTrace: org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285)\n",
       "org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)\n",
       "org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)\n",
       "org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n",
       "org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n",
       "org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n",
       "scala.Option.getOrElse(Option.scala:120)\n",
       "org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n",
       "org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n",
       "org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n",
       "org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n",
       "scala.Option.getOrElse(Option.scala:120)\n",
       "org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n",
       "org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1307)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
       "org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
       "org.apache.spark.rdd.RDD.take(RDD.scala:1302)\n",
       "org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1342)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
       "org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
       "org.apache.spark.rdd.RDD.first(RDD.scala:1341)\n",
       "$line35.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:38)\n",
       "$line35.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)\n",
       "$line35.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)\n",
       "$line35.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:47)\n",
       "$line35.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:49)\n",
       "$line35.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:51)\n",
       "$line35.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:53)\n",
       "$line35.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:55)\n",
       "$line35.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:57)\n",
       "$line35.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:59)\n",
       "$line35.$read$$iwC$$iwC$$iwC.<init>(<console>:61)\n",
       "$line35.$read$$iwC$$iwC.<init>(<console>:63)\n",
       "$line35.$read$$iwC.<init>(<console>:65)\n",
       "$line35.$read.<init>(<console>:67)\n",
       "$line35.$read$.<init>(<console>:71)\n",
       "$line35.$read$.<clinit>(<console>)\n",
       "$line35.$eval$.<init>(<console>:7)\n",
       "$line35.$eval$.<clinit>(<console>)\n",
       "$line35.$eval.$print(<console>)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "java.lang.reflect.Method.invoke(Method.java:497)\n",
       "org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
       "org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
       "org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
       "java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
       "java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
       "java.lang.Thread.run(Thread.java:745)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prettify(raw.first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"block\" : {\n",
       "    \"block_id\" : \"000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f\",\n",
       "    \"block_height\" : 0,\n",
       "    \"tx_number\" : 1,\n",
       "    \"difficulty\" : 1,\n",
       "    \"header\" : {\n",
       "      \"hash\" : \"000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f\",\n",
       "      \"version\" : 1,\n",
       "      \"prevHash\" : \"0000000000000000000000000000000000000000000000000000000000000000\",\n",
       "      \"merkleRoot\" : \"4a5e1e4baab89f3a32518a88c31bc87f618f76673e2cc77ab2127b7afdeda33b\",\n",
       "      \"time\" : 1231006505,\n",
       "      \"bits\" : 486604799,\n",
       "      \"nonce\" : 2083236893\n",
       "    }\n",
       "  },\n",
       "  \"tx\" : [ {\n",
       "    \"hash\" : \"4a5e1e4baab89f3a32518a88c31bc87f618f76673e2cc77ab2127b7afdeda33b\",\n",
       "    \"version\" : 1,\n",
       "    \"inputs\" : [ {\n",
       "      \"prevTxId\" : \"0000000000000000000000000000000000000000000000000000000000000000\",\n",
       "     ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val r1 = sc.textFile(\"hdfs://hadoop.loc/blockchain/0.json\")\n",
    "prettify(r1.first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullBlock(Block(000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f,0,1,1.0,BlockHeader(000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f,1,0000000000000000000000000000000000000000000000000000000000000000,4a5e1e4baab89f3a32518a88c31bc87f618f76673e2cc77ab2127b7afdeda33b,1231006505,486604799,2083236893)),List(Tx(4a5e1e4baab89f3a32518a88c31bc87f618f76673e2cc77ab2127b7afdeda33b,000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f,1231006505,1,List(),List(TxOutput(5000000000,65 0x04678afdb0fe5548271967f1a67130b7105cd6a828e03909a67962e0ea1f61deb649f6bc3f4cef38c4f35504e51ec112de5c384df7ba0b8d578a4c702b6bf11d5f OP_CHECKSIG,false)),0)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.first"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Toree - Scala",
   "language": "scala",
   "name": "toree_scala"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
